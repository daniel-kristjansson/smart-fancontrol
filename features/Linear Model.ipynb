{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7ccc8d-62f9-41d9-bc40-89a5441c5e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.experimental import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce8b0fd-b5b1-401e-998f-e134ec56157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b233fd2-f0f0-475e-8fd5-a8d740a553cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-26afd228aacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlogical_gpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Physical GPUs,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogical_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Logical GPUs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.11/envs/smart-fancontrol/lib/python3.6/site-packages/tensorflow/python/framework/config.py\u001b[0m in \u001b[0;36mlist_logical_devices\u001b[0;34m(device_type)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mLogicalDevice\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m   \"\"\"\n\u001b[0;32m--> 450\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.11/envs/smart-fancontrol/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mlist_logical_devices\u001b[0;34m(self, device_type)\u001b[0m\n\u001b[1;32m   1413\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[0;34m\"\"\"Return logical devices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logical_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.11/envs/smart-fancontrol/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m         pywrap_tfe.TFE_ContextOptionsSetRunEagerOpAsFunction(\n\u001b[1;32m    554\u001b[0m             opts, self._run_eager_op_as_function)\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "# Uncomment the following to disable GPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "print(tf.config.get_visible_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38dfd52-f0bc-4c60-ba9e-fbad33f7b3a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8cbf7-1c85-42a8-9ac1-e96ecb5cdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pq.ParquetDataset(\"/var/log/fancontrol/featurelog\")\n",
    "ptable = ds.read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807f4aa-3d3e-4e33-95e7-2e4ec8d2b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of outliers in power feture\n",
    "def clamp(num, min_value, max_value):\n",
    "   return max(min(num, max_value), min_value)\n",
    "power = ptable['power'].apply(lambda a: clamp(a[0], 0.0, 99.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0215f5-5d23-4e0f-8655-54fd5a3aa2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_names():\n",
    "    l = list(ptable.columns.values)\n",
    "    l.remove('label')\n",
    "    return l\n",
    "\n",
    "def generator_types():\n",
    "    return ({k: tf.float32 for k in feature_names()}, tf.float32)\n",
    "\n",
    "def dim(val):\n",
    "    return 1 if isinstance(val, float) or isinstance(val, int) else len(val)\n",
    "\n",
    "def generator_shapes():\n",
    "    _, row = next(ptable.iterrows())\n",
    "    shapes = {k: (1, dim(row[k])) for k in feature_names()}\n",
    "    return tuple([shapes, (1,)])\n",
    "\n",
    "print(feature_names())\n",
    "print(generator_types())\n",
    "print(generator_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d0d44-a7a4-4ca2-82ac-3b0356cbf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(key, value):\n",
    "    if isinstance(value, float) or isinstance(value, int):\n",
    "        return tf.reshape(tf.convert_to_tensor(value, tf.float32, name=key), (1, 1))\n",
    "    return tf.reshape(tf.convert_to_tensor(value, tf.float32, name=key), (1, dim(value)))\n",
    "\n",
    "def generator():\n",
    "    for index, row in ptable.iterrows():\n",
    "        f = {k: convert(k, row[k]) for k in feature_names()}\n",
    "        l = tf.convert_to_tensor(list([float(row['label'])]), tf.float32, name='label')\n",
    "        yield f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8e2da-bc88-4eb4-84ad-f5c4785d7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all = tf.data.Dataset.from_generator(generator, output_types=generator_types(), output_shapes=generator_shapes()) \\\n",
    "    .shuffle(10, reshuffle_each_iteration=False)\n",
    "n = next(all.batch(2).as_numpy_iterator())\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199cb24-4adf-41db-87be-6ec1fed7e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(n[0]['temp']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76b715-6c1f-435d-802a-a6503be03ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(n[1]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845e8f7-7134-4102-8a50-bc75fc42e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_test(x, y):\n",
    "    return x % 4 == 0\n",
    "def is_train(x, y):\n",
    "    return not is_test(x, y)\n",
    "recover = lambda x,y: y\n",
    "test_dataset = all.enumerate() \\\n",
    "                    .filter(is_test) \\\n",
    "                    .map(recover)\n",
    "\n",
    "train_dataset = all.enumerate() \\\n",
    "                    .filter(is_train) \\\n",
    "                    .map(recover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d1ca7-2918-4b2b-b841-9bb0defa052f",
   "metadata": {},
   "source": [
    "# Lets build a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e7e8a-4ddf-4b18-a4fb-529e08cf2d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1982d4a-4e83-4f02-bbea-baa6efd21211",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = Input(shape=(10,), name=\"temp\")\n",
    "cpu_idle_input = Input(shape=(8,), name=\"cpu_idle\")\n",
    "power_input = Input(shape=(1,), name=\"power\")\n",
    "fan_input = Input(shape=(1,), name=\"fan_rpm\")\n",
    "all_input = [power_input, temp_input, cpu_idle_input, fan_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c99ef2-3fdb-4a00-8f97-b8797d501721",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.concatenate(all_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491bb7c-3e98-4a3c-b090-45756e7292b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fanlevel_output = Dense(1, name=\"level\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30997a7-48f7-4036-af17-dd9f9d85b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model=keras.Model(inputs=all_input, outputs=[fanlevel_output])\n",
    "linear_model.compile(optimizer='adam', loss='msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93854fca-d568-4cd3-a7c2-1b7dc41a8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(linear_model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbcc55-d689-442f-a8d5-a05fd76a33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(train_dataset, epochs=1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988e3f2-c07b-4b43-89ed-05809ed2935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.save(\"first_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
